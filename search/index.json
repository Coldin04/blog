[{"content":" \u0026ldquo;核心想法：车停着充电的时候，让它用闲置算力复盘今天开得不好的地方，然后只把\u0026rsquo;错题本\u0026rsquo;传回云端。\u0026rdquo;\n⚠️ 前排叠甲 / Disclaimer： 关于本文的定位\n本文内容属于 \u0026ldquo;Vibe Writing\u0026rdquo; 和 \u0026ldquo;Vibe Talking\u0026rdquo; —— 类似于 Vibe Coding 的概念，即通过与 AI（Claude 和 Gemini）深度讨论、碰撞想法后整理而成的思维产物。\n我是谁：\n一个普通的计算机学生，非自动驾驶专业出身 一个 FSD 视频的观察者，对端到端自动驾驶有浓厚兴趣 一个喜欢\u0026quot;第一性原理思考\u0026quot;的技术爱好者 本文是什么：\n✅ 一次基于公开信息和第一性原理的思维实验 ✅ 一个关于\u0026quot;如何更好地利用车端算力\u0026quot;的技术构想 ✅ 一种跨界视角，试图为行业提供一个新的思考角度 本文不是什么：\n❌ 不是严谨的工程方案或技术白皮书 ❌ 不是对现有方案的批评或否定 ❌ 不是基于内部资料的行业分析 关于技术细节的说明\n已知事实：\n特斯拉 FSD 已在使用\u0026quot;视觉思考\u0026quot;（World Model）预测行人行为、规划复杂轨迹 车载芯片（如 Nvidia Orin X）的算力和功耗数据是公开的 推测与估算：\n文中关于\u0026quot;离线复盘\u0026quot;的具体实现路径是基于现有技术的推测 量化数据（如功耗、时间、压缩比）是基于公开参数的粗略估算 这些推测可能过于理想化，实际工程中可能面临未知挑战 AI 辅助的角色：\n本文的技术细节部分由 Gemini 和 Claude 辅助梳理和补充 AI 可能产生\u0026quot;幻觉\u0026quot;（即看似合理但未经验证的内容） 所有内容已尽力基于公开信息和逻辑推理，但仍请带着批判性思维阅读 如果你是专业人士\n欢迎指正文中的错误或不当之处 欢迎补充更专业的见解 欢迎告诉我\u0026quot;这个在行业里已经有人做了\u0026quot; 本文的价值\n核心价值在于\u0026quot;方向\u0026quot;而非\u0026quot;细节\u0026quot;：\n提出\u0026quot;利用车端闲置算力进行离线深度复盘\u0026quot;这一思路 探讨\u0026quot;如何在边缘侧提升数据价值\u0026quot;的可能性 为数据闭环提供一个不同的视角 具体实现细节，交给真正的专业团队去验证和优化。\n📧 联系方式：me@cold04.com\n💬 欢迎讨论：如果你对这个想法有任何想法、质疑或建议，欢迎在评论区或通过邮件交流。\n调查了一下目前的智驾行业落地情况，尚未发现有车企大规模利用车辆在充电/闲置状态下的算力进行边缘侧的深度复盘。基于目前 端到端（End-to-End） 模型、 边缘计算 和硬件特性的思考，我构想了一个技术路径：利用“闲置算力”对在线实时推理时遇到的“不优雅”关键点，进行一次“离线重算”。这本质上是借助“思考链”（Chain-of-Thought）模式进行深度复盘（System 2），以探索更优的解决方案。\n核心逻辑如下：\n触发机制：定义“值得复盘”的瞬间 逻辑： 定义需要进行“离线深思”的触发边界。核心是识别那些模型表现不佳或人类驾驶员感到“紧张”的瞬间。这些“高价值负样本”或“高博弈场景”是模型进化的关键养料。具体可量化的触发条件包括：\n模型内在不确定性（Model-related）： 预测概率发散： 模型输出的多个轨迹规划（Trajectory）或行为决策（Decision）的置信度非常接近，没有绝对优胜者，导致输出概率分布变得“扁平”。 输出抖动/震荡： 模型在短时间内（如连续几帧）给出的规划指令相互冲突，例如方向盘指令在小范围内高频左右摆动。 驾驶行为突变（Driver-related）： 强干预（Takeover）： 人类驾驶员突然且大幅度地介入，例如扭矩超过一定阈值的方向盘输入，或刹车踏板开度（Brake Pedal Position）的急剧变化。这通常意味着模型当时的决策与人类预期严重不符。 “心流”中断： 通过驾驶员监控系统（DMS）检测到驾驶员的视线突然从道路前方移开，开始频繁检查后视镜或侧方，或表现出紧张情绪。 场景复杂度（Scene-related）： 高动态交互： 在无保护左转、人车混流的窄巷、或遇到“鬼探头”（Sudden Cut-in）等场景时，即使模型和人都处理得很好，这些高交互博弈场景本身也值得复盘。 感知罕见物（Corner Case）： 感知模块识别到低置信度但可能影响安全的物体，如路上的异形障碍物、非标准交通参与者（如滑板、轮椅）等。 操作： 一旦触发，系统并非立即开始计算，而是在后台将该事件点前后一段时间（如 触发前10秒 + 触发后5秒）的 高保真传感器数据（Raw Sensor Data） 进行快照（Snapshot）和标记，存入本地的“复盘任务队列”。\n技术理由： 类似于人类的“瞬间集中注意力”或“事后诸葛亮”。数据清洗不应该只在云端后处理，更应该在端侧利用实时上下文进行预筛选，这既解决了“海量数据中的长尾挖掘”问题，也极大地节省了数据回传的带宽成本。\n执行时机与用户激励：\n时机: “复盘任务队列”的计算和上传，被设计在车辆的“深度休眠”时段执行，尤其是夜间在家中使用充电桩充电时。此时车辆有稳定的电力和网络，可以从容进行深度计算。 激励: 为鼓励车主授权，厂商可提供明确的“回报”。例如，车主贡献高质量的复盘数据后，可获得奖励，如 100公里 的高阶辅助驾驶里程、免费超充额度或积分。这能建立正向循环：用户贡献数据 → 模型进化 → 体验提升 → 激励用户更多使用，最终形成一个活跃的、由用户驱动的“数据飞轮”。 对标与超越: 这套机制也是对现有方案（如特斯拉“影子模式”）的补充和深化。当发现“影子模式”决策与驾驶员不符时，传统做法是记录上传。本构想则更进一步：不仅记录“差异”，更在本地利用“思考链”重新推理，尝试找到一个可能超越“影子模式”和驾驶员的更优解，提供价值更高的训练数据。 与现有方案的对比与互补 已知的类似机制：\n根据公开信息，特斯拉的影子模式（Shadow Mode）会在以下情况触发数据收集：\n人类接管（Disengagement） 模型决策与人类操作显著不同 感知到罕见物体或异常场景 本方案的扩展：\n本构想在此基础上增加了三个维度的触发条件：\n维度 特斯拉影子模式 本方案扩展 模型内部状态 不透明 增加\u0026quot;概率分布扁平化\u0026quot;、\u0026ldquo;输出抖动\u0026quot;等内部不确定性指标 驾驶员心理 仅检测接管 增加 DMS 检测的\u0026quot;心流中断\u0026rdquo;（紧张情绪、视线转移） 场景价值 被动触发 主动标记高博弈场景（如无保护左转），即使处理得好也复盘 互补性而非替代性：\n本方案不是要取代传统的\u0026quot;记录-上传\u0026quot;模式，而是作为补充：\n80% 的规划决策问题：上传轻量级的 {场景-解法} 数据对（本方案） 20% 的感知失效问题：上传高保真的原始传感器数据（传统方案） 两种方案结合，才能形成完整的数据闭环。\n执行过程：从“在线伴驾”到“离线复盘” 逻辑： 现有的**影子模式（Shadow Mode）**是在驾驶中实时运行，拿模型预测与人类操作做对比。此构想则将其升级：既然车载芯片（如 Orin X）能在毫秒级的实时压力下运行一次推理，那么在停车/充电的“离线”状态下，它完全有能力、有时间进行上千次探索性推理，把“下棋”变成“复盘棋局”。\n操作（Step-by-step）：\n任务激活（Activation）： 前置条件： 由一个轻量级的后台“任务调度器”来管理。它的激活条件被严格限定在夜间家充等车辆深度休眠时段。具体检查清单包括：车辆处于 P 档、已连接到常用位置的充电桩、正在充电且 SoC \u0026gt; 80%、并且车载计算单元温度适宜。满足所有条件后，任务调度器才从“复盘任务队列”中取出标记的事件，开始执行深度复盘。 优先级排序： 任务队列可根据事件的“熵值”或“严重性”进行排序，优先复盘最具价值的场景。 环境重建（World Reconstruction）： 数据源： 利用存储的 Raw Data——这包括触发点前后所有摄像头（如8路4K）的原始视频帧、IMU（惯性测量单元）数据、GPS信号、以及激光雷达/毫米波雷达的点云信息。 构建沙盒： 在车载芯片上构建一个物理和语义上一致的数字孪生沙盒（Digital Twin Sandbox）。它需要精确复刻触发事件时的动态环境，但这一步无疑是整个构想中最具挑战性的一环。沙盒的保真度强依赖于车载感知模型的准确性，这意味着如果初始感知出错（例如，将异形物识别为普通车辆），那么后续的推演都将基于错误的前提。因此，感知的上限，决定了模拟的上限。 技术现实性讨论：\n\u0026ldquo;世界模型\u0026quot;并非空中楼阁：\n根据公开信息：\n特斯拉 FSD：已在使用\u0026quot;视觉思考\u0026rdquo;（Visual Thinking）机制，能够预测行人行为（\u0026ldquo;这个人会不会突然横穿\u0026rdquo;）、规划复杂轨迹（K字形掉头、精准对准麦当劳点餐窗口） 这意味着：现代端到端模型已经具备了\u0026quot;世界模型\u0026quot;的雏形。\n本方案的假设：\n如果模型在实时驾驶中（毫秒级延迟压力下）就能进行\u0026quot;视觉思考\u0026quot;，那么在离线状态下（无实时性压力），它完全可以：\n加载更大的模型：使用更复杂的网络结构，提升推理精度 运行更多次推理：探索成百上千种可能的决策路径 进行更深的\u0026quot;思考链\u0026quot;：从单步预测扩展到多步博弈推演 关键限制（必须承认）：\n⚠️ \u0026ldquo;世界模型\u0026quot;的准确性取决于感知能力：\n如果初始感知就有偏差（如将异形物误识别），后续推演也会基于错误前提 这就是\u0026quot;垃圾进，垃圾出\u0026rdquo;（GIGO）原则 因此，离线复盘的结果必须经过云端的二次验证 ⚠️ 无法完美预测人类行为：\n模型可以预测\u0026quot;合理的行为\u0026quot;，但无法预测\u0026quot;所有可能的行为\u0026quot; 因此，复盘的价值在于\u0026quot;探索更优策略\u0026quot;，而非\u0026quot;保证绝对正确\u0026quot; 评估标准：\n世界模型的好坏，不应该用\u0026quot;是否完美预测了现实\u0026quot;来衡量，而应该用\u0026quot;基于它优化出的策略，在云端大规模验证后，是否在现实中表现更好\u0026quot;来衡量。\n类比：就像 AlphaGo 的\u0026quot;价值网络\u0026quot;不需要完美预测每一步棋的结果，但它能帮助 AlphaGo 找到更好的下法。\n3. **反事实推演（Counterfactual Search）：** - **切换模式与解锁算力：** 模型不再有 `几十毫秒` 的实时性要求，可以加载更复杂的策略（Policy），从 **`System 1`（直觉反应）** 切换到 **`System 2`（深度思考）** 模式，并充分利用芯片的所有计算单元。这个过程，本质上就是在应用一种 **“思考链”（Chain of Thought）** 的模式。 - **多策略探索：** 在“思考链”的指引下，系统不再满足于单一的最优解，而是进行多策略探索。以人类驾驶员的实际操作（或模型自身的在线决策）为“基线”，利用 **蒙特卡洛树搜索（MCTS）** 等方法，在本地的轻量级世界模型中探索数千种“what-if”的可能性。这里的“世界模型”必然是简化版，无法完美预测复杂的人类博弈，但仍可用于探索物理上可行且更优的轨迹。 - **迭代评估与剪枝：** 每一种推演出的轨迹都会通过一个精细的 **成本函数（Cost Function）** 进行评估，该函数综合考量了安全性、效率、舒适性、合规性等多个维度。但在此过程中，必须正视 **“垃圾进，垃圾出”（Garbage In, Garbage Out）** 的核心风险——基于错误感知前提的优化，其结果在现实世界中可能毫无意义。此外，大规模的探索性推理也会带来额外的功耗和硬件负载，需要在数据价值与硬件损耗之间做出智能权衡。明显更差的“分支”会被剪枝，算力将集中于寻找更优解。 关于功耗与硬件负载的量化分析：\n⚠️ 重要说明：以下数字基于公开资料和理论推算，实际情况可能因模型复杂度、芯片优化等因素有较大差异。本估算仅用于说明\u0026quot;功耗在可接受范围内\u0026quot;这一结论，不作为工程设计依据。\n基础数据（来源：Nvidia 官方资料）：\n芯片：Nvidia Orin X 算力：254 TOPS（万亿次运算/秒） 功耗：~60W（满负载时） 假设场景：\n假设每天驾驶中触发 10 个\u0026quot;值得复盘\u0026quot;的场景：\n每个场景需要进行 1000 次不同策略的推理（探索空间） 每次推理耗时 50ms（是实时推理的 5 倍，因为使用了更复杂的模型） 计算过程：\n总推理时间：\n1 10 场景 × 1000 次推理 × 50ms = 500,000ms ≈ 8.3 分钟 总功耗：\n1 60W × 8.3 分钟 ≈ 8.3 Wh（瓦时） 占电池容量比例：\n1 2 电动车电池容量通常为 60-100 kWh 8.3 Wh ≈ 0.01% 的电池容量 结论：\n即使按照这个保守估算（1000 次推理可能已经过多），功耗也几乎可以忽略不计。\n实际情况可能更好：\n如果推理时间更短（芯片优化、模型剪枝） 如果不需要 1000 次推理（通过剪枝算法，可能 100-200 次就够了） 如果任务分散在整个充电周期（4-8 小时），平均功耗更低 散热管理：\n有人可能担心芯片长时间高负载运行会过热。实际上：\n时间分散：复盘任务不是连续 8 分钟满负载，而是分散在整个充电过程中 温度监控：任务调度器会实时监控芯片温度，接近阈值就暂停任务 对比实时驾驶：实时驾驶时，芯片需要持续高负载运行（处理 8 路摄像头、实时推理、渲染界面等）。相比之下，离线复盘的负载更低、更可控 生成“优化策略包”（Generate Solution Pair）： 寻找最优解： 经过数千次模拟，一旦找到一条或多条显著优于“基准线”行为的帕累托最优轨迹（Pareto-optimal Trajectory），系统便会停止搜索。 数据封装： 最终，它会打包生成一个高度压缩、信息密集的“策略包”。其中不仅包含 { 原始问题场景, 最终优化轨迹 }，还可能附带“成本函数降低了多少”、“关键决策节点的差异”等元数据，形成一个完整的“案例分析报告”。 因此，从功耗和散热角度看，技术上是完全可行的。\n技术理由（防怼关键点）： 算力可行性： 硬件既然支持实时推理，就一定支持离线模拟。这本质上是 “算力的时分复用”，将闲置资源转化为有价值的数据洞察。 安全性： 所有推演都在100%安全的数字沙盒中进行，允许模型在不影响物理世界的前提下，探索更高风险、更高回报的策略边界。 价值提纯： 相比于上传原始的“问题数据”，这种方式直接上传了经过端侧算力验证的“题解”，极大提升了上传给云端的数据质量和信噪比。 数据闭环：高信噪比的上传策略 逻辑： 解决“云端算力无限但带宽有限”与“端侧数据最全但算力受限”的核心矛盾，将数据闭环的重心从“传输”转向“计算”，实现价值的提纯。\n操作（Step-by-step）：\n数据封装与序列化（Data Encapsulation \u0026amp; Serialization）： 在讨论具体的数据结构前，必须先明确本方案的适用边界。它主要用于优化 “规划与决策（Planning \u0026amp; Decision-making）” 链路。对于因 “感知（Perception）” 错误导致的疑难场景（例如，未能识别出路上的罕见障碍物），云端算法团队依然强依赖高保真的原始传感器数据（Raw Sensor Data）来复现问题、分析原因。\n因此，一个更完备的数据闭环系统必然是 混合式 的：对规划决策问题，优先采用本方案上传轻量级的{场景-解法}数据对；而当系统检测到可能是感知模型失效时，则应触发一小段高保真Raw Data的上传请求，作为关键补充。\n定义数据结构： 基于此定位，上传的ScenarioSolutionPair数据包应高度结构化，其核心可包含：\nProblem (Scenario): scene_metadata: 场景元数据（时间戳、地理位置、天气等）。 initial_state: 车辆初始状态（速度、加速度、朝向）。 dynamic_objects_bev: 关键帧的鸟瞰图（BEV）视角下的动态物体列表，每个物体包含ID、类别、位置、速度矢量、尺寸（Bounding Box）。 static_environment_map: 静态环境的向量地图，如车道线、路沿、交通标志等。 Solution (Suggested Trajectory): original_trajectory: 作为基线的原始轨迹（人类或模型的在线决策）。 optimized_trajectory: 端侧推演出的帕累托最优轨迹序列，由一串 (x, y, heading, velocity, timestamp) 航点组成。 decision_metadata: 决策元数据，如“该轨迹相比基线，在安全性/效率/舒适性上的成本函数得分变化”、“关键决策节点的差异分析”等。 数据压缩： 轨迹数据（Trajectory）可以采用 差分编码（Delta Compression） 进行压缩，只记录航点间的变化量，进一步减小数据包体积。\n压缩技术的具体方案：\n1. 轨迹数据压缩：\n方法 1 - 关键帧提取：只存储关键帧（如转向点、加减速点），中间用样条曲线（Spline）插值 方法 2 - 相对坐标：用相对坐标而非绝对坐标（减少数值范围，提高压缩率） 方法 3 - 定点数：在精度允许的情况下，用定点数而非浮点数 2. BEV 数据压缩：\n方法 1 - 增量存储：只存储\u0026quot;变化的物体\u0026quot;（静态背景不存） 方法 2 - 矢量化表示：用多边形描述车辆轮廓，而非栅格化的像素数据 方法 3 - 语义压缩：用语义描述（如\u0026quot;一辆白色轿车，位置 (x, y)，速度 v\u0026quot;）替代完整的像素数据 预期效果：\n数据类型 原始大小 压缩后大小 压缩比 10秒原始视频（8路1080p） ~100 MB - - 结构化场景描述 + 轨迹 - ~100 KB 1000:1 说明：\n压缩比 1000:1 是基于\u0026quot;只传输结构化数据，不传输原始视频\u0026quot;的理想情况\n实际压缩比可能因场景复杂度而异，但数量级上的优势是明确的\n智能上传与带宽管理（Intelligent Upload \u0026amp; Bandwidth Management）：\n触发与调度： 上传任务由后台“任务调度器”统一管理，仅在车辆连接到Wi-Fi、处于充电状态或用户指定的时间段内触发，避免消耗昂贵的蜂窝数据流量。 优先级队列： 根据场景的“价值”（如接管严重性、模型不确定性得分）对 ScenarioSolutionPair 数据包进行排序，确保最高价值的“错题本”优先上传。 云端验证与数据增强（Cloud Validation \u0026amp; Augmentation）：\n规模化再验证： 云端收到数据包后，会利用远超车载算力的 大规模世界模型（Large-Scale World Model） 进行二次验证。它不仅确认端侧方案的优越性，更会在一个更复杂、更真实的模拟环境中（例如，加入更多随机车辆、模拟不同天气光照）测试该方案的鲁棒性。 自动化数据增强： 一旦验证通过，这个高质量的 Pair 就成了一个“黄金样本”。云端训练平台可以基于此场景，自动生成数百个相似但细节不同的衍生场景（what-if scenarios），例如“如果当时行人速度再快一点会怎样？”，从而将一个高质量样本的价值放大百倍。 模型迭代与闭环（Model Iteration \u0026amp; Loop Closure）： 需要强调的是，整个“学习”过程发生在云端，车端的角色始终是执行“深度重推理”的“数据预处理器”，而非进行“模型训练”或“微调”。\n生成训练标签： 经过验证和增强的“最优轨迹”被转化为高质量的监督学习标签。 模型重训练/微调： 这些标签被送入下一代模型的训练流程中，用以优化模型的策略网络（Policy Network），最终通过 OTA 更新部署到整个车队，从而完成整个 Edge-Cloud 的数据驱动闭环。 技术理由：\n带宽效率： 通过端侧预计算和结构化封装，将需要上传的数据量减少了几个数量级，避免了 Raw Data 上传的巨大带宽浪费。 信息密度最大化： 上传的不再是原始数据，而是经过“粗加工”和“提纯”的信息结晶。本地数据包含最丰富的上下文（Context），在本地消化数据远比传到云端再分析高效（Data Gravity 原则——移动算力比移动数据便宜）。 信噪比革命： 从根本上改变了自动驾驶数据挖掘的范式，从“大海捞针”式的被动收集，转变为“目标明确”的主动生成，极大提升了训练数据的信噪比和迭代效率。 远景展望：从“离线复盘”到“在线自进化” 如果说“离线复盘”是让车辆学会“总结错题”，那么一个更激动人心的远景，是赋予车辆在安全边界内“在线学习”的潜力。\n⚠️ 重要说明：以下内容属于更远期的技术展望，涉及端侧模型微调，存在更高的技术和安全挑战。这不是本文的核心方案，仅作为思路延伸。\n这需要对硬件和模型架构提出新的构想：例如，能否利用智能座舱域（Smart Cockpit Domain）中那颗性能强大但非安全关键（Non-Safety-Critical）的芯片，来承担“离线微调”的重任？\n关键安全原则：\n端侧微调必须在严格的安全框架下进行：\n主干模型不可变：\n负责实际驾驶的\u0026quot;主干模型\u0026quot;是固化的，经过严格验证，不允许任何修改 这就像操作系统的内核，必须保证绝对稳定 微调只影响\u0026quot;策略适配模块\u0026quot;：\n微调的是一个轻量级的\u0026quot;补丁\u0026quot;（如 LoRA），它只调整模型的\u0026quot;偏好\u0026quot;，而不改变基础能力 类比：就像给一个司机换了一副眼镜，他的驾驶技能没变，但看得更清楚了 微调模型不直接控制车辆：\n微调后的模型只在\u0026quot;影子模式\u0026quot;下运行，不掌握方向盘 它的作用是\u0026quot;提供建议\u0026quot;，而不是\u0026quot;直接执行\u0026quot; 云端验证与回滚机制：\n端侧微调的结果会定期上传到云端，由专业团队验证 如果发现问题，可以远程回滚到原始模型 用户授权与透明度：\n用户可以选择是否启用\u0026quot;端侧微调\u0026quot;功能 系统会清晰地告知用户\u0026quot;当前使用的是微调模型\u0026quot; 其核心思路，并非要直接修改那个经过严格安全验证的基础模型（Base Model），这在安全合规上是绝对不允许的。相反，我们可以借鉴开源社区中类似Android内核GKI（Generic Kernel Image）或Magisk/KSU的“系统层与模块层分离”的哲学。\n模型架构的模块化： 设想未来的自动驾驶模型由两部分组成：一个固化的、通过严格验证的“主干模型”，以及一个可动态加载的“策略适配模块”。这个适配模块可以采用类似 LoRA（Low-Rank Adaptation） 的技术，通过训练一个极小的、低秩的“补丁”矩阵，来高效地微调模型的行为，而无需改动庞大的主干模型权重。车辆在端侧进行的微调，实际上就是生成和更新这个“LoRA补丁”，既实现了在线学习，又保证了主干模型的绝对安全。\n“双模型”影子模式： 当未来的车载算力足够充裕时（例如，足以同时运行两个甚至更多的推理任务），一种新的、更强大的“影子模式”成为可能：\n驾驶员A（原始模型）： 这是官方发布的、负责实际车辆操控的、经过完整验证的驾驶模型。 驾驶员B（微调模型）： 这就是在端侧，通过持续的离线复盘与在线学习，动态微调了“策略模块”后的模型。它就像一个永远在学习、不断进化的“影子司机”，与原始模型一起思考，但并不掌握方向盘。 更高维的数据闭环： 在这种模式下，车辆不再仅仅上传“人类开得如何”或“我（原始模型）开得如何”，而是上传一种更高维度的对比数据：{ 场景, 原始模型决策, 微调模型决策, 人类决策 }。这种数据直接体现了模型在端侧“自我进化”的方向和效果，对于云端进行大规模模型融合与迭代，其价值不可估量。\n当然，这套体系的建立，还需要一系列配套的技术，例如AI时代的“可信标签”方案，用以验证端侧微调的有效性。但这无疑为自动驾驶的终极形态——能够像人类一样不断适应和进化的“老司机”——描绘出了一条激动人心的技术路径。\n总结 本文提出了一个基于 “边缘-云端” 协同的自动驾驶数据闭环新构想。其核心是，与其将所有原始数据传回云端，不如利用车载闲置算力，在端侧进行一次 “离线重算”。通过类似 “思考链”（Chain of Thought） 的模式，对在线推理时遇到的不完美决策进行深度复盘，从而将车辆从被动的“数据采集器”升级为主动的“策略优化器”。\n该构想的本质，是充分利用车辆在充电或泊车时的 闲置算力，将 Inference-time Compute（推理时计算） 的概念延伸到数据挖掘领域。具体路径如下：\n端侧（Edge）： 通过智能定义的触发器，精准捕获高价值的疑难场景（Corner Case），并在本地安全的数字孪生沙盒中进行大规模的 “离线深度复盘”。这允许模型从实时的“直觉”决策（System 1）切换到深度的“反事实推演”（System 2），探索并生成更优的解决方案。 云端（Cloud）： 接收由端侧“预处理”和“提纯”后的 {场景-解法} 数据对。这种高信噪比的结构化数据，极大地节省了回传带宽，并从根本上提升了训练样本的质量和有效性。云端再利用其强大算力进行二次验证、增强和模型重训练。 最终，这个框架将海量、低效的原始数据流，转变为一股精确、高效的“黄金样本”流，有望加速端到端模型的收敛与迭代。它重新定义了车载计算单元的价值——不仅是行驶中的“大脑”，更是停车时的“专属陪练”与“数据精炼厂”。\n关于\u0026quot;为什么（据我所知）没有车企大规模应用\u0026quot;的思考 ⚠️ 重要前提：我作为一个外部观察者，无法获取车企的内部信息。以下纯属个人推测，可能完全错误。\n可能的原因：\n技术成熟度：\n端到端模型本身还在快速迭代 \u0026ldquo;让它先能开\u0026quot;比\u0026quot;让它开得更好\u0026quot;更紧迫 世界模型的准确性可能还未达到可用于大规模离线复盘的程度 工程复杂度：\n需要重新设计数据闭环架构 需要在车载系统中增加任务调度、热管理、数据压缩等模块 需要云端配合建立新的数据验证和增强流程 商业优先级：\n车企的首要任务是\u0026quot;通过法规\u0026quot;和\u0026quot;避免事故\u0026rdquo; 数据闭环的优化是长期投资，短期内看不到明显收益 相比之下，增加传感器、升级芯片等\u0026quot;硬件升级\u0026quot;更容易营销 可能已经有人在做，但没有公开：\n特斯拉的影子模式可能已经朝这个方向演进 Waymo 等公司的仿真系统可能已经在做类似的事情 但作为核心竞争力，通常不会对外公开技术细节 我的信息盲区：\n我可能完全不知道行业内已经有成熟方案 我可能不了解某些技术或法规层面的障碍 欢迎业内人士指正 但无论如何，我认为这个方向值得探索。\n因为它符合一个基本原则：\n在数据产生的地方处理数据，永远比传到远方再处理更高效。\n这是分布式计算、边缘计算的核心思想，也应该适用于自动驾驶的数据闭环。\n","date":"2026-01-26T17:52:39+08:00","permalink":"https://blog.cold04.com/p/videa-edge-counterfactual/","title":"【思考随笔】关于利用车端闲置算力进行“离线影子模式”与数据闭环的构想"},{"content":"基础知识（先把底层逻辑讲明白） 一、从“块”开始：Cache 是什么？为什么要映射？ 如果你还不知道 Cache 是啥，可以把它理解成：\nCPU 旁边的一小块“超快内存”（容量小但速度快） 主存（内存）很大但更慢 CPU 运行时会频繁读/写内存。为了避免每次都去“慢的主存”取数据，硬件会把最近用过、很可能马上还会用到的数据，先放进 Cache。\n为什么 Cache 不是“按一个字节/一个字”搬运，而是“按块（Block）”搬运？ 因为程序往往有 局部性（Locality）：\n* **时间局部性**：刚用过的数据，可能马上还会用。 * **空间局部性**：访问了地址 A，往往很快也会访问 A 附近的地址。 所以 Cache 和主存交换数据时，通常一次把一整段连续地址搬上来，这段连续地址就叫一个 块（Block）。\n举个最直观的例子：\n块大小 = 16B 你读取地址 0x1000 的 1 个字节 硬件往往会把 0x1000 ~ 0x100F 这 16B 整块放进 Cache。 这样你接下来再访问 0x1001、0x1002……就很可能直接命中（hit）。\n“映射（Mapping）”到底在干嘛？ 关键矛盾只有一句：Cache 容量远小于主存。\n主存里有海量的块，但 Cache 里只有有限的“位置”能放块（这些位置叫 行 Line）。于是必须规定：\n“主存的某个块，进 Cache 时允许放到哪些行（或哪些组 Set）里？”\n这个规定就是 映射方式。\n不同映射方式的区别，就体现在：\n- 允许放的位置越多：越不容易互相顶掉（冲突少），但查找/硬件更复杂。 - 允许放的位置越少：查找更快/硬件更简单，但更容易冲突（两个热块老挤一个位置）。 这页只讲一件事：一段内存地址（或内存块）到底怎么“放进”Cache。\n二、一次访问到底发生什么：Hit/Miss 机制 很多同学卡住不是因为公式，而是因为不知道“算出来的 Tag/Index 到底拿去干嘛”。下面给你一个能直接套题的流程。\nCache 一行（Line）里通常有什么 把一行想成一个小盒子，里面至少有：\nValid 位：这行里有没有装过有效数据（没装过就一定 miss）。 Tag：这行当前装的是“主存的哪一个块”。 Data（数据块）：真正的块内容。 可能还会有（看题目/课程深度，知道即可）：\nDirty 位：写回法（write-back）时用，表示这行数据是否被改过。 替换信息：比如 LRU 需要的“最近使用情况”。 一次读/写访问的标准流程（最重要） 不管直接映射/全相联/组相联，流程本质都一样，只是“要检查的行数”不同：\n算块地址 BlockAddr：先把地址按块大小折算成“这是第几个块”。\n根据映射方式定位候选位置：\n直接映射：候选 = 1 行（算出 LineIndex）。 组相联：候选 = 1 组内的 k 行（算出 SetIndex）。 全相联：候选 = 全部行（没有 Index）。 命中判定（Valid + Tag 比较）：\n如果某个候选行 Valid=1 且 Tag 匹配：Hit。 否则：Miss。 Hit 之后怎么取数据：用 Offset 在这行的 Data 里取到块内对应的字节/字。\nMiss 之后会发生什么（装入/替换）：\n从主存把“目标块”取到 Cache。 若候选位置有空行：直接放进去。 若没有空行：按替换策略（LRU/FIFO/随机）选一个受害者（victim）顶掉。 若采用写回法且 victim 的 Dirty=1：先把 victim 写回主存，再覆盖。 一张“从地址到命中/缺失”的流程图（ASCII 版） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 CPU 发起一次访存（给你一个地址 Addr） | v 按块大小切：BlockAddr = floor(Addr / BlockSize) | v 按映射方式定位候选位置（行/组）： - 直接映射：LineIndex = BlockAddr mod NumLines - 组相联： SetIndex = BlockAddr mod NumSets（组内 k 路都要查） - 全相联： 候选 = 全部行 | v 在候选行里做命中判定： 若存在某行：Valid=1 且 Tag 匹配 ---\u0026gt; HIT 否则 ---\u0026gt; MISS | | | v | 选空行或按替换策略挑 victim | | | (若 write-back 且 victim Dirty=1 则先写回) | | | v | 从主存取目标块，装入 Cache | | v v 用 Offset 取块内数据/完成读写 重新访问（这次通常会 hit） 写策略（题目不考细节也能看懂） 写操作常见两对策略（题目若没说，通常只考映射/命中率，写策略可忽略）：\nWrite-through（写直达）：写 Cache 同时写主存（简单但慢）。 Write-back（写回）：先只写 Cache，换出时再写回（快但要 Dirty 位）。 Write-allocate（写分配）：写 miss 也把块先装入 Cache 再写（常见）。 No-write-allocate：写 miss 不装入 Cache，直接写主存（某些场景用）。 三、术语对齐：块（Block）/ 行（Line）/ 组（Set） 块（Block）：Cache 和主存交换数据的最小单位。题目常给“块大小 = 4 字 / 16B”等。 行（Line）：Cache 里存放一个块的位置。有时也叫“Cache 块”。 组（Set）：组相联里的一组“行”。例如 2 路组相联 = 每组 2 行。 你只要记住：\n直接映射：每个主存块只能去 Cache 的“唯一一行”。 全相联：每个主存块可以去 Cache 的“任意一行”。 组相联：每个主存块只能去“唯一一组”，但在组里可以去“任意一行”。 四、三种映射方式总览（先建立直觉） 方式 主存块能放到哪里 查找速度 硬件成本 常见缺失类型 直接映射 (Direct Mapped) 固定 1 行 最快 最低 冲突缺失明显 全相联 (Fully Associative) 任意行 最慢 最高 基本无冲突缺失 组相联 (Set Associative) 固定 1 组 + 组内任意行 居中 居中 冲突缺失缓解 缺失（Miss）通常分三类（考试高频）：\n强制缺失（Compulsory/Cold Miss）：第一次访问某块必 miss。 容量缺失（Capacity Miss）：Cache 总容量不够，装不下要用的块。 冲突缺失（Conflict Miss）：容量够，但“映射规则”把多个块挤到同一行/同一组。 五、地址怎么切：Tag / Index / Offset 题目常写：\n$$ \\text{Address} = \\text{Tag} \\parallel \\text{Index} \\parallel \\text{Offset} $$含义（按字节寻址的经典默认）：\nOffset（块内偏移）：你要这个块里的第几个字节/字。 Index（索引）：去 Cache 的哪一行（直接映射）/哪一组（组相联）。 Tag（标记）：用来确认“这一行/这一组里装的到底是哪一个主存块”。 三种映射方式（核心） 块地址（Block Address）：\n$$ \\text{BlockAddr} = \\left\\lfloor \\frac{\\text{MemAddr}}{\\text{BlockSize}} \\right\\rfloor $$ 直接映射：\n$$ \\text{LineIndex} = \\text{BlockAddr} \\bmod \\text{NumLines} $$ $k$ 路组相联（$k$-way）：\n$$ \\text{SetIndex} = \\text{BlockAddr} \\bmod \\text{NumSets},\\quad \\text{NumSets}=\\frac{\\text{NumLines}}{k} $$ 小提示：如果题目给的访问序列看起来像 16,17,18,19 ... 这种“连续加 1”，很可能给的是字地址或字节地址；你要先用块大小把它们折算成块地址（上面的 BlockAddr）。\n一、直接映射（Direct Mapped） 规则（一句话版） 每个主存块只能映射到 Cache 的唯一一行：\n$$ \\text{LineIndex} = \\text{BlockAddr} \\bmod \\text{NumLines} $$做题时你在做什么 先算这个访问属于哪个 BlockAddr。\n再用取模算出它去 哪一行。\n去那一行比对 Tag：\nTag 相同：命中（Hit） Tag 不同或空：缺失（Miss），把新块塞进来（旧的被直接踢掉）。 直观图 二、全相联（Fully Associative） 规则（一句话版） 主存块可以进 Cache 的任意一行，所以 没有 Index（或 Index 长度为 0）。\n做题时你需要注意什么 命中判定：要在“所有行”里找 Tag（硬件用并行比较，题目里就理解为“全表查”）。 缺失时：必须有 替换策略（LRU/FIFO/随机）。题目不说通常默认随机或 LRU（看老师口径）。 直观图 三、组相联（Set Associative） 规则（一句话版） 主存块只能去唯一一组，但可以放到组内任意一路（way）：\n$$ \\text{SetIndex} = \\text{BlockAddr} \\bmod \\text{NumSets} $$2 路组相联：你脑中应该出现的画面 Cache 被分成很多组（Set）。 每组里有 2 行（2 way）。 来了一个块：先用取模找到组号；再在这组里两行都比 Tag。 直观图 题目与练习（把分数拿到手） 一、一个极小例子把三种方式“算通” 假设（为了演示简单）：\nCache 一共 4 行 块大小 = 1（忽略 Offset） 访问的块序列：0, 4, 0, 4 直接映射（4 行） LineIndex = BlockAddr mod 4 0 和 4 都映射到行 0 结果：0 miss，4 miss（顶掉 0），0 miss（顶掉 4），4 miss 全是 miss：典型的冲突缺失 全相联（4 行） 0、4 都能进任意行 结果：0 miss，4 miss，0 hit，4 hit 2 路组相联（4 行 = 2 组 × 2 路） NumSets=2，SetIndex=BlockAddr mod 2 0 和 4 都落到组 0，但组 0 有 2 路 结果：0 miss，4 miss（组0 还装得下），0 hit，4 hit 二、题目分析 Cache：2 路组相联 Cache 总行数：32 行（块） 块大小：4 字（word） 地址位宽：16 位（本题命中率计算不一定用到位宽） 访存序列（看起来是“字地址”）： 16 17 18 19 144 145 146 147 252 253 465 466 第一步：把“地址”先变成“块地址 BlockAddr” 块大小是 4 字，所以每 4 个连续字地址属于同一个块：\n$$ \\text{BlockAddr} = \\left\\lfloor \\frac{\\text{WordAddr}}{4} \\right\\rfloor $$把序列换成块地址：\n16~19 都在块 $\\lfloor 16/4 \\rfloor = 4$ 144~147 都在块 $\\lfloor 144/4 \\rfloor = 36$ 252~253 都在块 $\\lfloor 252/4 \\rfloor = 63$ 465~466 都在块 $\\lfloor 465/4 \\rfloor = 116$ 所以块序列是：\n4,4,4,4, 36,36,36,36, 63,63, 116,116\n第二步：算组号（2 路组相联） 总行数 32，2 路 $\\Rightarrow$ 组数：\n$$ \\text{NumSets} = 32/2 = 16 $$ 组号：\n$$ \\text{SetIndex} = \\text{BlockAddr} \\bmod 16 $$ 计算：\n块 4：$4\\bmod 16=4$（组 4） 块 36：$36\\bmod 16=4$（组 4） 块 63：$63\\bmod 16=15$（组 15） 块 116：$116\\bmod 16=4$（组 4） 注意：4、36、116 三个块都挤在同一组（组 4），这就是本题的“冲突热点”。\n第三步：按替换策略判 Hit/Miss（假设初始 Cache 为空，组内 LRU） 访问块 4：miss（把块 4 装入组 4） 再访问块 4 三次：hit、hit、hit（同一块内连续访问，体现空间局部性） 访问块 36：miss（组 4 还有空位，装入） 再访问块 36 三次：hit、hit、hit 访问块 63：miss（装入组 15） 再访问块 63 一次：hit 访问块 116：miss（组 4 满了，需要替换；LRU 会踢掉“更久没用”的块 4） 再访问块 116 一次：hit 统计：\n总访问：12 次 miss：4 次（第一次见到块 4 / 36 / 63 / 116） hit：8 次 命中率：\n$$ \\text{HitRate} = \\frac{8}{12} = \\frac{2}{3} \\approx 66.7\\% $$这题在考你什么 块大小带来的空间局部性：16~19 一次装块后后面 3 次都 hit。 组相联缓解冲突：虽然 4、36、116 都落同一组，但 2 路能同时容纳其中两个。 替换策略影响细节：如果后续又访问块 4，就会因为刚才被踢掉而 miss。 三、举一反一（一个正例 + 一个反例） 正例：先“算块地址”再“算组号/行号” 题设：块大小 4 字，访问字地址 145。\n块地址：$\\lfloor 145/4 \\rfloor = 36$ 2 路组相联，32 行 $\\Rightarrow$ 16 组 组号：$36\\bmod 16=4$ 结论：它一定在组 4（组内哪一路要看替换策略与当前内容）。\n反例：把“字地址”当成“块地址”直接取模（常见低级错） 错误做法：直接拿 145 mod 16 = 1，说它在组 1。\n为什么错？\n因为 Cache 映射是按“块”为单位的。 145 是块内的一个字地址，它属于块 36；映射应该用 36 去取模，而不是用 145。 ","date":"2025-12-27T10:00:00+08:00","permalink":"https://blog.cold04.com/p/cache_mapping/","title":"Cache 三种映射方式（直接/全相联/组相联）"},{"content":"前言 用腻了Android手机，总想逃回苹果生态。虽然Android自由安装应用的特性异常好用，但各家品牌各自为政，所谓“碎片化”严重，有时候统一的体验反而更重要。\n你问为什么要选择iPhone SE3？的确，性价比对我来说是首位的，类似865的性能对我来说完全够用，毕竟我最多算轻度游戏玩家。那最劝退的呢？显然是捉襟见肘的续航了。\n用机偏好 在选择手机的时候，最重要的还是需要考虑好自己的用机需求和相关的偏好。对于我来说，很方便的就可以观察到，我在使用手机的时候，娱乐和即时通讯是耗电的大头，而其他的需求，例如扫码使用小程序，购物，生活，打车等生活服务类的应用，使用频率并不高。但如果观察存储占用，前者的占用反而并不高，反而是后者占用的存储空间更大。可以总的概括为，装80%的应用，完成20%的事。\n为什么选择iPhone SE3 如果你要问大部分人为什么选择，可能会告诉你：“因为便宜啊！”但对我来说。确实是这样的，但也不完全是。要便宜的话，安卓阵营的选择更多，但我更看重apple生态带来的便利体验。此外，我还有一台小米10，作为那个”装20%应用”的手机，这样一来，我只需要一台无修改的设备来完成大部分的轻度应用即可。综合来看，我在iPhone 13 mini和iPhone SE3之间犹豫了很久，最终选择了iPhone SE3。\n使用体验 拿到手上的第一感觉就是轻巧，现在的手机普遍又大又重，拿起这么小的手机，一下子手部的负担小了很多。单手操作也很轻松，甚至可以用大拇指完成大部分的操作。\n对于这个16:9的屏幕比例，看惯了那么多全面屏，对我来说看回来也并不会觉得有什么不适应，反而觉得很舒服。但在2025年的今天，开发者在开发应用的时候可能并不会考虑16:9屏幕的显示效果，毕竟从iPhone X发布到现在已经7年过去了，16:9的屏幕比例已经很少见了。好在大部分应用都能适配，偶尔会遇到一些应用界面显示不全的情况，适配不全的情况一般来源于跨平台开发的应用，但好在于暂时没有遇到影响使用的情况。\n续航方面，确实是iPhone SE3的短板，毕竟电池容量摆在那里。但好在我对手机的使用并不重度，一般都能在手机电量不足时及时给手机“续命”。对于这么小的手机来说，用一个20w的充电器就足够了，充电速度也很快。\n拍照 虽然说SE3的摄像头并不出色，但对于拍摄文档和扫码、随手拍来说是完全够用的。对于这个摄像头，我最满意的反而是文档拍摄的清晰度。现在部分手机（如小米10）在拍摄文档的时候，边缘可能会有发虚的情况，而iPhone SE3则不会出现这种情况，拍摄的文档清晰度很高。\neSIM 值得一提的是，这台手机的外版是支持eSIM的，那就很方便的，可以将我用于接受验证码的eSIM放在上面，收到短信的时候可以一键填充，十分方便。\n总结 总的来说，iPhone SE3是一款非常适合轻度用户的手机，尤其是对于那些需要一台便携、轻巧且能够满足日常使用需求的用户来说，iPhone SE3无疑是一个不错的选择。虽然续航是它的短板，但对于我这样的使用习惯来说，完全可以接受。但如果你问我是否推荐，其实我并不会。这台手机其实只适合作为大部分人的“备用机”，甚至连备用机都不能上榜。续航是他的短板，但在其他方面，其实这是一台很均衡的，来源于旧时代的旗舰手机。即时他有现代化的A15处理器，现代化的eSIM功能，但他渐渐的也和这个时代格格不入了。\n","date":"2025-09-06T15:00:00+08:00","permalink":"https://blog.cold04.com/p/iphone_se3_up/","title":"iPhone SE3 上手体验，续航和便携的碰撞"},{"content":"今天临时起意，遂购买co1d.in。\n当初准备在namesilo购买，不过一比价，发现Spaceship更便宜，遂换这家服务商。\n因此，现已可通过:\nco1d.in 访问我的主页 b.co1d.in 访问我的博客 n.co1d.in 访问我的笔记 ","date":"2024-12-22T14:34:48Z","permalink":"https://blog.cold04.com/p/domain_co1d/","title":"购入新域名，现在可以更畅快的访问我的主页!"},{"content":"前段时间正在愉快的对电脑进行维护，但一不小心手滑敲错了命令，导致我用了两年的Windows系统盘被无意清空。因为之前有备份文件的习惯，所以对我的损失并不算大。但由于Blog的源文件存储在家里的机械盘中，找回不那么方便，加上感觉之前的主题有些较旧了，索性打算好好的重建一下Blog。\n搜寻适合自己的静态网站生成器 开始的时候，我仍打算使用Hexo作为博客的生成器，于是考虑搜寻一个好看且较贴切个人风格的主题。但无意中看到了 Hugo，便本着尝鲜的想法，打开的Hugo的官网进行查看。于是第一步，就开始挑选主题。说起来可能有那么些不可思议，我第一眼便相中了 Hugo Theme Stack 这个主题，设计风格简单明了，也没有多余的元素，而且更好的是，他可以直接使用 Hugo Theme Stack Starter 导入自己的Github仓库，并可以借助 Github Action 进行自动编译文章。这样一来，确实可以简化不少的工作流程，方便我随时随地使用CodeSpace更新文章。就好比这篇文章，我就使用Surface远程CodeSpace进行编辑的。\n配置网站和熟悉逻辑 这部分其实没那么多好说的，我就是按照自己的风格进行调试，你可以在Github Commits里面看到我相关操作，因此没那么多可以聊的，按照帮助配置就好。\n迁移文章和遇到的问题 网站按照自己的想法配置好后，就到了迁移文章的时候。前面说过，因为源文件丢失了，所以网站内容我都是直接从老Blog 复制粘贴下来的。因为前面的文章没有引用图片，所以开始并没有注意到问题，直到我开始迁移《记一次数据恢复和数据冷备份》 这篇文章的时候，才发现通过外链引用的图片居然打不开（心想，wtf，难道这个框架不支持图片的预览嘛），开始以为是配置没有开导致的，直到我开始看官方文档，直到我注意到\n1 2 3 4 5 WARNING Inserting external images is supported, but it is not recommended. Features like image gallery and image zooming will not work with external images. Those feature needs to know the image\u0026#39;s dimensions, which is not possible with external images. 啊？我当时注意到这个的时候还挺震惊的，因为我的习惯就是从外链引用图片，这下子确实麻烦起来了,甚至让我有了放弃使用的想法。不过好在经过简单搜索，发现了 Hugo Theme Stack图库是怎么工作的？怎样才能支持外链图片？ 这篇文章。\n不过即使找到了解决方案，也没法修改。显而易见的是，我的仓库里并没有layouts文件夹，更别谈去修改了。我又开始打起了退堂鼓，不过之后又进行了一番搜索，发现官方的仓库中也说明了这一情况，但没说明白。通过Hugo Modules 方式加载，可以通过新建这个目录，本地的文件会自动覆盖编译时加载的文件。这个设计太赞了！于是，按照解决方案修改好之后，在config.toml中按照规则关闭imageProcessing.content改成false并添加有关项目，再次测试发现外链图片可正常查看了。\nHugo的优势 用一个字形容就是\u0026quot;快\u0026quot;，而且并不需要像node.js那样在每次安装依赖时都弄得很复杂。这个主题支持使用Github Action编译，也使得我在每次写完之后可以只管上传就行，流程方面也能更快了。总而言之，这个工作流让我很满意。下一步来说，我应该会考虑专注于创作点优质的Blog内容，而系统化的内容仍会在 酷丁的笔记 中持续更新。\n","date":"2024-04-29T09:00:00+08:00","permalink":"https://blog.cold04.com/p/new_blog/","title":"Blog翻新，更优雅的界面，更舒适的工作方式"},{"content":"前言 最初，家里的一些老照片和老的资料是放在老电脑的硬盘中。不巧的是，老电脑的硬盘可能是被误格式化，导致资料丢失。刚放假的时候，出于想尝试的目的，以及想要找回一些资料的目的，我尝试了一下数据恢复，自此开始，我开始构建自己的资料冷备份体系。\n首先说明，我对资料的备份和恢复懂的并不多，这里记录的方法可能是错的或者并不是最适合你的方法，只是希望记录下来，以便以后查阅。欢迎各位大佬指正。\n数据恢复 因为数据之前有部分被覆写，加上硬盘也被重新格式化了，因此，我选择使用DiskGenius恢复数据，最终，我成功找到了不少资料和一些照片。但因为数据部分被覆盖，很多照片都丢失了。由此可见，数据无价并不是闹着玩的。\n当时我操作的方法也很土，使用Ventoy启动了我移动硬盘中的Win to go系统，然后在Win to go系统中安装了DiskGenius，最后使用DiskGenius恢复数据。这种方法的好处是不用拆机，但因为在老电脑上运行，速度显然受到了老电脑机能的限制。不过经过一个下午的时间，经过筛选后，也找到了不少资料。\n从DiskGenius中恢复的资料，我将其放在了移动硬盘中，但这些资料没有文件名，需要手动整理。为了不让自己太累，我直接让Copilot辅助我写了一个小程序，来用于将word文档中的标题作为文件名。这样，我就可以直接通过文件名来找到我想要的资料了。\n同样，表格文件也借助了差不错的方法解决。自此，资料初步整理完成。\n冷备份老资料 显然，放在我的移动硬盘中以及电脑中也不是长久之际，我有定期清理空间的习惯。另外，移动硬盘存在丢失的风险。在网上浏览一圈之后，看到了“冷备份”这个词。由此，我开始挑选备份介质。\n挑选介质 首先必须明确一点，目前因为预算方面问题，我的预算并不太够。幸运的是，目前来说，我需要冷备份的资料并不是很多，也并不需要太大的储存空间。不过考虑到介质可能很久才打开检查一次，我根据需要选择机械硬盘。\n可能去看大部分博主的推荐，都会告诉你，目前4TB以下的机械硬盘都不那么推荐。不过考虑到预算和上述的实际需求，经过多方面学习，最终选择了2块全新的西数的1TB紫盘来完成我的任务。\n读取硬盘，目前我选用的是绿联的硬盘盒。建议替换自带的电源，但我目前预算不足，没有替换。\n拷贝资料 我没有组Raid的条件，故我选择手动“镜像”两个盘的文件。我先拆封了一个盘，在电脑上整理好所有资料，使用fastcopy将资料复制到硬盘目录。使用fastcopy纯粹是因为他可以在拷贝资料的时候校验，拷贝大文件的时候也相对较快，体验较好。\n在弹出硬盘时，注意先在电脑上选择弹出，等待数秒保证硬盘停转和磁头归位后，关闭硬盘盒电源并拔出硬盘。这样做，一方面可以防止硬盘还在读写，另一方面，磁头离开硬盘盘面后，可以防止移动时磁头划伤硬盘，变成“唱片机”。\n定期查看和写入资料 一般来说，每个阶段之后，都需要将一些资料进行备份。我建议周期是半年到一年定期检查下。当然，有重要资料的时候，也别忘记写入，时间有限的话，也可以一同检查下硬盘的smart值。\n对于用于备份的机械硬盘来说，smart值还挺重要的，有时候smart出现警告后，要及时考虑转移资料和选择新硬盘进行备份。\n总结 对于每个人来说，都有或多或少的重要资料。永远要记住：“数据无价”。定期做好数据备份是一项不错的选择，不要等到失去了再追悔莫及。\n这里有个小插曲，我在3月份的时候，无意中格式化了Windows系统盘。因为备份习惯，导致我的资料和进度丢失并不算太多，所以还是那句话，数据无价，勤备份才是王。\n","date":"2024-01-29T09:00:00+08:00","permalink":"https://blog.cold04.com/p/data_cold_backup/","title":"记一次数据恢复和数据冷备份"},{"content":"问题描述 在使用mysql_secure_installation命令时，出现以下错误：\n1 ERROR 2002 (HY000): Can\u0026#39;t connect to local MySQL server through socket \u0026#39;/var/lib/mysql/mysql.sock\u0026#39; (2 \u0026#34;No such file or directory\u0026#34;) 问题分析 显而易见的是，1mysql_secure_installation1命令无法连接到本地的MySQL服务，原因是MySQL服务没有启动。\n但在之前的操作步骤中，已经使用了systemctl start mariadb命令启动了MySQL服务，为什么还是无法连接呢？\n进入目录查看可知，在此目录下无/var/lib/mysql/mysql.sock文件。\n使用 find / -name 'mysql.sock' 命令查找，发现文件在/tmp/mysql.sock（部分在/tmp/sys…/tmp/mysql.sock 之下）。\n解决方法 先使用 find / -name 'mysql.sock' 命令查找mysql.sock文件，找到文件所在目录。\n复制这个目录，为其创建软链接，如下：\n1 ln -s /tmp/sys.../tmp/mysql.sock（这里写的是你复制的目录） /var/lib/mysql/mysql.sock 再次尝试使用mysql_secure_installation命令，问题解决。\n多说两句 其实，在新版的Mysql/MariaDB中，修改密码的方式有所变更，使用mysql_secure_installation命令修改密码的方式已经不再适用。具体可以看这里\n新版初始化可以考虑手动初始化:\n1 2 3 4 mysql(如果之前有密码则加上有关内容) ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;新密码\u0026#39;; flush privileges; exit; ","date":"2023-11-21T21:00:00+08:00","permalink":"https://blog.cold04.com/p/mysql_error_2002/","title":"解决mysql_secure_installation ERROR 2002"},{"content":"兄弟这两天忽然找我，他们实验室服务器因为配置原因，无法直接访问外网，但是他们需要下载一些东西，于是就想到了使用代理。因为一台机器中存在多个用户，自然不能在系统中直接配置代理，经过一翻查找，就想到了使用proxychains。\n基本环境 简介也说明了，因为实验室的服务器提供给多人使用，部分用户是没有管理员权限的（避免因此造成不必要的麻烦），所以不能在系统中直接配置代理，这样一方面是对路由资源会造成损耗，另一方面，也不太方便在代理和直连之间切换。所以，使用proxychains是一个不错的选择。\n安装proxychains 因为实验室服务器使用的是Debian，所以使用apt安装即可。\n1 sudo apt install proxychains 配置proxychains 一般来说，proxychains的配置文件在/etc/proxychains.conf，但是我们强调，因为上述特殊环境，我们需要在不同用户下使用不同的配置，所以我们需要在用户目录下创建配置文件，这样就可以实现不同用户使用不同的配置。\n1 vim ~/.proxychains/proxychains.conf 在这个配置文件中，我们需添加以下内容:\n1 2 [ProxyList] socks5 127.0.0.1 1080 username password 其中，username和password是你的代理服务器的用户名和密码，如果没有，可以不填写。服务器地址和端口可按照需求修改。\n使用proxychains 使用proxychains很简单，只需要在命令前加上proxychains即可，例如:\n1 proxychains git clone https://github.com/Coldin04/NoteShare.git 或者，也有另外一种方式：proxychains bash\n这样，就可以在一个新的bash中使用代理了。\n测试连通性： 注意：如果使用的是socks5代理，因为socks5代理处于第五层，所以ping命令是无法使用的，只能使用curl或者wget等命令。 proxychains curl cip.cc\n参考资料 [1] proxychains-ng [2] Linux 配置 ProxyChains 本地代理\n","date":"2023-10-30T22:00:00+08:00","permalink":"https://blog.cold04.com/p/proxychains/","title":"配置ProxyChains，使得终端可以使用代理"},{"content":"自从转到计算机专业之后，因为很多命令在电脑上执行，故开始尝试使用了Obsidian记录笔记。一个学期下来，也攒了不少内容。本着分享的精神，我最初的想法是将Obsidian仓库发布，也方便对笔记进行备份。后来发现，Obsidian的第三方发布服务均有一定的缺陷，而官方发布服务又需要付费，价格又不太理想，很长一段时间都放弃去做这个事情了。\n后来，在看到一些文档的的时候，发现了很多人都使用这一套“风格”进行搭建，如小林Coding 、ArchLinux简明指南 等。发现均以Vuepress为基础进行搭建，于是我也开始尝试使用Vuepress搭建自己的笔记库。（其实之前考虑过Notion等工具，但后来放弃）\nVuepress VuePress 由两部分组成：第一部分是一个极简静态网站生成器 (opens new window)，它包含由 Vue 驱动的主题系统和插件 API，另一个部分是为书写技术文档而优化的默认主题，它的诞生初衷是为了支持 Vue 及其子项目的文档需求。\n更多可以看官方文档。\n搭建过程 小插曲 其实，Vuepress的安装非常简单，只需要使用yarn即可:\n1 2 3 mkdir vuepress-starter \u0026amp;\u0026amp; cd vuepress-starter yarn init yarn add -D vuepress 当然，也别急着就开始了，想让网站更丰富，可以考虑安装第三方的主题。当然，如果想要了解更多安装和配置的细节，也可以进入官方文档 了解更多细节。\n我使用的是vuepress-theme-hope 这个主题，这个主题主题很大程度上继承了 VuePress 默认主题的配置，并在此基础上添加了大量功能与布局优化。而且，这个主题也有blog功能，有兴趣的话可以了解一下。\n标题说这是小插曲，那也就顺便聊聊。当时我拿到手，也是一股脑的按照上面的步骤安装了Vuepress，顺便熟悉了一下基本配置。我有个小习惯，当我正在研究的或者正在学习的东西（前提是感兴趣），我会去B站搜索看看别人的视频，或者去搜索引擎上以这个名称为关键词看看别人的配置过程这样的。无意就发现了Vuepress-theme-hope和Vuepress-theme-repo这两个主题。\n当我点开了这两者的搜索条目，才发现这两个主题并非像Wordpress或者Hexo那样导入进去，或者放入一个文件夹就能用，而是单独通过包管理器（pnpm或yarn）进行新建。后来，我含泪去转移了已经整理完成的笔记，不过这些的工作量也并不大就是。\n正式开始 安装 建议参考：小白教程 首先，保证安装了Node.js、yarn\\Pnpm和VS Code（或其他编辑器），然后根据提示安装即可。\n但我既然在这里提到这件事，说明我也遇到了一些问题，这里也顺便记录一下。\n在运行时，我首先遇到了这样的错误：\n1 2 3 Error [ERR_MODULE_NOT_FOUND]: Cannot find package \u0026#39;katex\u0026#39; imported from /home/coldin04/Documents/webnote/docs/node_modules/@mdit/plugin-katex/lib/index.mjs at new NodeError (node:internal/errors:406:5) ...... 这个错误的原因是因为vuepress-theme-hope的依赖包katex没有找到，查询后发现，可通过:yarn add katex解决。\ntips:之后查询到，这个依赖包是用于数学公式的，如果不需要，可以不安装，去配置中将其注释掉即可。\n然后，我又遇到了这样的错误：\n1 2 3 4 Error: Cannot find module \u0026#39;reveal.js/dist/reveal.css\u0026#39; Require stack: - /home/coldin04/Documents/xxx/@mr-hope/vuepress-plugin-pwa/lib/client.js ..... 这个错误的原因是因为vuepress-theme-hope的依赖包reveal.js没有找到，查询后发现，可通过:yarn add reveal.js解决。\n此时，如果执行yarn dev，若能够正常运行，则即可进行下一步进行仔细的配置了。当然，如果还有别的运行问题，也可以借助搜索引擎或类似于ChatGPT语言大模型进行解决。\n配置 因为Vuepress也配置过好几天了，具体也无法记的很详细了，这里就简单的说一下。当然，每个人的风格不同，配置是自然不同的，我的操作更多的是提供思路，请不要被我的步骤局限住了。\nbase 首当其冲的是配置这个选项，可参考Base。这个选项是用于设置网站的基础路径，如果你准备发布到 https://.github.io// ，也就是说你的仓库地址是 https://github.com// ，则将 base 设置为 “//“。\n导航栏 这个选项是用于设置导航栏的.\n显而易见的是，我的导航栏并没有什么特殊的设置，只是简单把写过的笔记进行分类整理，然后放在了导航栏中。\n侧边栏 对于侧边栏，我是选择了通过文件结构生成，毕竟因为是笔记站，这样配置起来，可以更方便的去查找笔记。不过随着之后内容的增多，也可能会考虑对不同笔记目录单独生成不同的侧边栏。\n评论 主要是因为懒 ，我选择直接将相关配置注释，关闭评论区，之后可能会考虑使用第三方评论系统。\nSEO 这个主题的一大优点，便是自带SEO功能，且默认是开启的，可参考SEO。\n对于其他功能，我也并没有去仔细关注，毕竟这个主题的配置项还是很多的，而且也不是每个人都需要的，对于笔记站来说，我觉得这些功能也并不是很重要，在之后的使用中，如果有需要，再去配置也不迟。\n结语 这个笔记站的搭建，也是我第一次使用Vuepress，也是第一次使用Vue，所以在搭建过程中，也遇到了很多问题，也是在解决问题的过程中，学习了很多知识。在这里，也希望能够帮助到其他人，也希望能够帮助到自己。\n在这次的配置过程中，确实让我整个人都得到了一个放松。前段时间状态确实不太行。在这次配置的过程中不断面对问题，解决问题，让我感到了久违的满足感和获得感。也让我重新找回了学习的乐趣。\n感谢vuepress、vuepress-theme-hope等开源项目的开发者，感谢他们的付出，让我能够使用这么好的工具。最后，也感谢你能够看到这里，希望你能够喜欢这个笔记站。\n","date":"2023-10-30T22:00:00+08:00","permalink":"https://blog.cold04.com/p/note-news/","title":"新站上线！用Vuepress搭建的个人笔记库"}]